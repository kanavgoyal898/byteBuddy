{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **bytebuddy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unicode code points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['h', 'e', 'l', 'l', 'o', ',', ' ', 'w', 'o', 'r', 'l', 'd'],\n",
       " [104, 101, 108, 108, 111, 44, 32, 119, 111, 114, 108, 100])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'hello, world'\n",
    "t = [ord(c) for c in s]\n",
    "s = [chr(i) for i in t]\n",
    "s, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unicode byte encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf\\xe4\\xb8\\x96\\xe7\\x95\\x8c'\n",
      "b'\\xff\\xfeS0\\x930k0a0o0\\x16NLu'\n",
      "b'\\xff\\xfe\\x00\\x00S0\\x00\\x00\\x930\\x00\\x00k0\\x00\\x00a0\\x00\\x00o0\\x00\\x00\\x16N\\x00\\x00Lu\\x00\\x00'\n"
     ]
    }
   ],
   "source": [
    "s = '„Åì„Çì„Å´„Å°„ÅØ‰∏ñÁïå'\n",
    "print(s.encode('utf-8'))\n",
    "print(s.encode('utf-16'))\n",
    "print(s.encode('utf-32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[227, 129, 147, 227, 130, 147, 227, 129, 171, 227, 129, 161, 227, 129, 175, 228, 184, 150, 231, 149, 140]\n",
      "[255, 254, 83, 48, 147, 48, 107, 48, 97, 48, 111, 48, 22, 78, 76, 117]\n",
      "[255, 254, 0, 0, 83, 48, 0, 0, 147, 48, 0, 0, 107, 48, 0, 0, 97, 48, 0, 0, 111, 48, 0, 0, 22, 78, 0, 0, 76, 117, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(list(s.encode('utf-8')))\n",
    "print(list(s.encode('utf-16')))\n",
    "print(list(s.encode('utf-32')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Hello, ‰∏ñÁïå! üåçüòä –ü—Ä–∏–≤–µ—Ç –º–∏—Ä! üöÄüåü ‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ! üéâüìö „Åì„Çì„Å´„Å°„ÅØ‰∏ñÁïå! üéåüêâ ÏïàÎÖïÌïòÏÑ∏Ïöî ÏÑ∏Í≥Ñ! üéµüñãÔ∏è\n",
      "length: 72\n",
      "----------\n",
      "[72, 101, 108, 108, 111, 44, 32, 228, 184, 150, 231, 149, 140, 33, 32, 240, 159, 140, 141, 240, 159, 152, 138, 32, 208, 159, 209, 128, 208, 184, 208, 178, 208, 181, 209, 130, 32, 208, 188, 208, 184, 209, 128, 33, 32, 240, 159, 154, 128, 240, 159, 140, 159, 32, 224, 164, 168, 224, 164, 174, 224, 164, 184, 224, 165, 141, 224, 164, 164, 224, 165, 135, 32, 224, 164, 166, 224, 165, 129, 224, 164, 168, 224, 164, 191, 224, 164, 175, 224, 164, 190, 33, 32, 240, 159, 142, 137, 240, 159, 147, 154, 32, 227, 129, 147, 227, 130, 147, 227, 129, 171, 227, 129, 161, 227, 129, 175, 228, 184, 150, 231, 149, 140, 33, 32, 240, 159, 142, 140, 240, 159, 144, 137, 32, 236, 149, 136, 235, 133, 149, 237, 149, 152, 236, 132, 184, 236, 154, 148, 32, 236, 132, 184, 234, 179, 132, 33, 32, 240, 159, 142, 181, 240, 159, 150, 139, 239, 184, 143]\n",
      "length: 169\n"
     ]
    }
   ],
   "source": [
    "text = 'Hello, ‰∏ñÁïå! üåçüòä –ü—Ä–∏–≤–µ—Ç –º–∏—Ä! üöÄüåü ‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ! üéâüìö „Åì„Çì„Å´„Å°„ÅØ‰∏ñÁïå! üéåüêâ ÏïàÎÖïÌïòÏÑ∏Ïöî ÏÑ∏Í≥Ñ! üéµüñãÔ∏è'\n",
    "tokens = text.encode('utf-8')   # raw bytes\n",
    "tokens = list(tokens)           # convert to a list of integers in range 0...255 for convenience\n",
    "print('----------')\n",
    "print(text)\n",
    "print('length:', len(text))\n",
    "print('----------')\n",
    "print(tokens)\n",
    "print('length:', len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
      "length: 445\n",
      "----------\n",
      "[76, 111, 114, 101, 109, 32, 105, 112, 115, 117, 109, 32, 100, 111, 108, 111, 114, 32, 115, 105, 116, 32, 97, 109, 101, 116, 44, 32, 99, 111, 110, 115, 101, 99, 116, 101, 116, 117, 114, 32, 97, 100, 105, 112, 105, 115, 99, 105, 110, 103, 32, 101, 108, 105, 116, 44, 32, 115, 101, 100, 32, 100, 111, 32, 101, 105, 117, 115, 109, 111, 100, 32, 116, 101, 109, 112, 111, 114, 32, 105, 110, 99, 105, 100, 105, 100, 117, 110, 116, 32, 117, 116, 32, 108, 97, 98, 111, 114, 101, 32, 101, 116, 32, 100, 111, 108, 111, 114, 101, 32, 109, 97, 103, 110, 97, 32, 97, 108, 105, 113, 117, 97, 46, 32, 85, 116, 32, 101, 110, 105, 109, 32, 97, 100, 32, 109, 105, 110, 105, 109, 32, 118, 101, 110, 105, 97, 109, 44, 32, 113, 117, 105, 115, 32, 110, 111, 115, 116, 114, 117, 100, 32, 101, 120, 101, 114, 99, 105, 116, 97, 116, 105, 111, 110, 32, 117, 108, 108, 97, 109, 99, 111, 32, 108, 97, 98, 111, 114, 105, 115, 32, 110, 105, 115, 105, 32, 117, 116, 32, 97, 108, 105, 113, 117, 105, 112, 32, 101, 120, 32, 101, 97, 32, 99, 111, 109, 109, 111, 100, 111, 32, 99, 111, 110, 115, 101, 113, 117, 97, 116, 46, 32, 68, 117, 105, 115, 32, 97, 117, 116, 101, 32, 105, 114, 117, 114, 101, 32, 100, 111, 108, 111, 114, 32, 105, 110, 32, 114, 101, 112, 114, 101, 104, 101, 110, 100, 101, 114, 105, 116, 32, 105, 110, 32, 118, 111, 108, 117, 112, 116, 97, 116, 101, 32, 118, 101, 108, 105, 116, 32, 101, 115, 115, 101, 32, 99, 105, 108, 108, 117, 109, 32, 100, 111, 108, 111, 114, 101, 32, 101, 117, 32, 102, 117, 103, 105, 97, 116, 32, 110, 117, 108, 108, 97, 32, 112, 97, 114, 105, 97, 116, 117, 114, 46, 32, 69, 120, 99, 101, 112, 116, 101, 117, 114, 32, 115, 105, 110, 116, 32, 111, 99, 99, 97, 101, 99, 97, 116, 32, 99, 117, 112, 105, 100, 97, 116, 97, 116, 32, 110, 111, 110, 32, 112, 114, 111, 105, 100, 101, 110, 116, 44, 32, 115, 117, 110, 116, 32, 105, 110, 32, 99, 117, 108, 112, 97, 32, 113, 117, 105, 32, 111, 102, 102, 105, 99, 105, 97, 32, 100, 101, 115, 101, 114, 117, 110, 116, 32, 109, 111, 108, 108, 105, 116, 32, 97, 110, 105, 109, 32, 105, 100, 32, 101, 115, 116, 32, 108, 97, 98, 111, 114, 117, 109, 46]\n",
      "length: 445\n"
     ]
    }
   ],
   "source": [
    "text = 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.'\n",
    "tokens = text.encode('utf-8')   # raw bytes\n",
    "tokens = list(tokens)           # convert to a list of integers in range 0...255 for convenience\n",
    "print('----------')\n",
    "print(text)\n",
    "print('length:', len(text))\n",
    "print('----------')\n",
    "print(tokens)\n",
    "print('length:', len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **byte-pair encoding (BPE) algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(ids):\n",
    "    counts = {}\n",
    "    for pair in zip(ids, ids[1:]):      # pythonic way to iterate consecutive elements\n",
    "        counts[pair] = counts.get(pair, 0) + 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(76, 111): 1, (111, 114): 9, (114, 101): 7, (101, 109): 2, (109, 32): 6, (32, 105): 7, (105, 112): 3, (112, 115): 1, (115, 117): 2, (117, 109): 3, (32, 100): 6, (100, 111): 6, (111, 108): 6, (108, 111): 4, (114, 32): 5, (32, 115): 4, (115, 105): 3, (105, 116): 6, (116, 32): 16, (32, 97): 7, (97, 109): 3, (109, 101): 1, (101, 116): 3, (116, 44): 3, (44, 32): 4, (32, 99): 6, (99, 111): 4, (111, 110): 4, (110, 115): 2, (115, 101): 5, (101, 99): 2, (99, 116): 1, (116, 101): 5, (116, 117): 2, (117, 114): 4, (97, 100): 2, (100, 105): 2, (112, 105): 2, (105, 115): 5, (115, 99): 1, (99, 105): 5, (105, 110): 7, (110, 103): 1, (103, 32): 1, (32, 101): 10, (101, 108): 2, (108, 105): 5, (101, 100): 1, (100, 32): 5, (111, 32): 3, (101, 105): 1, (105, 117): 1, (117, 115): 1, (115, 109): 1, (109, 111): 3, (111, 100): 2, (32, 116): 1, (109, 112): 1, (112, 111): 1, (110, 99): 1, (105, 100): 5, (100, 117): 1, (117, 110): 3, (110, 116): 5, (32, 117): 3, (117, 116): 3, (32, 108): 3, (108, 97): 5, (97, 98): 3, (98, 111): 3, (101, 32): 7, (32, 109): 3, (109, 97): 1, (97, 103): 1, (103, 110): 1, (110, 97): 1, (97, 32): 5, (97, 108): 2, (105, 113): 2, (113, 117): 5, (117, 97): 2, (97, 46): 1, (46, 32): 3, (32, 85): 1, (85, 116): 1, (101, 110): 4, (110, 105): 5, (105, 109): 3, (109, 105): 1, (32, 118): 3, (118, 101): 2, (105, 97): 4, (109, 44): 1, (32, 113): 2, (117, 105): 4, (115, 32): 3, (32, 110): 4, (110, 111): 2, (111, 115): 1, (115, 116): 2, (116, 114): 1, (114, 117): 4, (117, 100): 1, (101, 120): 2, (120, 101): 1, (101, 114): 3, (114, 99): 1, (116, 97): 3, (97, 116): 8, (116, 105): 1, (105, 111): 1, (110, 32): 5, (117, 108): 3, (108, 108): 4, (109, 99): 1, (114, 105): 3, (105, 32): 2, (112, 32): 1, (120, 32): 1, (101, 97): 1, (111, 109): 1, (109, 109): 1, (101, 113): 1, (116, 46): 1, (32, 68): 1, (68, 117): 1, (97, 117): 1, (105, 114): 1, (32, 114): 1, (101, 112): 2, (112, 114): 2, (101, 104): 1, (104, 101): 1, (110, 100): 1, (100, 101): 3, (118, 111): 1, (108, 117): 2, (117, 112): 2, (112, 116): 2, (101, 115): 3, (115, 115): 1, (105, 108): 1, (101, 117): 2, (117, 32): 1, (32, 102): 1, (102, 117): 1, (117, 103): 1, (103, 105): 1, (110, 117): 1, (32, 112): 2, (112, 97): 2, (97, 114): 1, (114, 46): 1, (32, 69): 1, (69, 120): 1, (120, 99): 1, (99, 101): 1, (32, 111): 2, (111, 99): 1, (99, 99): 1, (99, 97): 2, (97, 101): 1, (99, 117): 2, (100, 97): 1, (114, 111): 1, (111, 105): 1, (108, 112): 1, (111, 102): 1, (102, 102): 1, (102, 105): 1, (105, 99): 1, (97, 110): 1, (109, 46): 1}\n",
      "[(16, (116, 32)), (10, (32, 101)), (9, (111, 114)), (8, (97, 116)), (7, (114, 101)), (7, (105, 110)), (7, (101, 32)), (7, (32, 105)), (7, (32, 97)), (6, (111, 108)), (6, (109, 32)), (6, (105, 116)), (6, (100, 111)), (6, (32, 100)), (6, (32, 99)), (5, (116, 101)), (5, (115, 101)), (5, (114, 32)), (5, (113, 117)), (5, (110, 116)), (5, (110, 105)), (5, (110, 32)), (5, (108, 105)), (5, (108, 97)), (5, (105, 115)), (5, (105, 100)), (5, (100, 32)), (5, (99, 105)), (5, (97, 32)), (4, (117, 114)), (4, (117, 105)), (4, (114, 117)), (4, (111, 110)), (4, (108, 111)), (4, (108, 108)), (4, (105, 97)), (4, (101, 110)), (4, (99, 111)), (4, (44, 32)), (4, (32, 115)), (4, (32, 110)), (3, (117, 116)), (3, (117, 110)), (3, (117, 109)), (3, (117, 108)), (3, (116, 97)), (3, (116, 44)), (3, (115, 105)), (3, (115, 32)), (3, (114, 105)), (3, (111, 32)), (3, (109, 111)), (3, (105, 112)), (3, (105, 109)), (3, (101, 116)), (3, (101, 115)), (3, (101, 114)), (3, (100, 101)), (3, (98, 111)), (3, (97, 109)), (3, (97, 98)), (3, (46, 32)), (3, (32, 118)), (3, (32, 117)), (3, (32, 109)), (3, (32, 108)), (2, (118, 101)), (2, (117, 112)), (2, (117, 97)), (2, (116, 117)), (2, (115, 117)), (2, (115, 116)), (2, (112, 116)), (2, (112, 114)), (2, (112, 105)), (2, (112, 97)), (2, (111, 100)), (2, (110, 115)), (2, (110, 111)), (2, (108, 117)), (2, (105, 113)), (2, (105, 32)), (2, (101, 120)), (2, (101, 117)), (2, (101, 112)), (2, (101, 109)), (2, (101, 108)), (2, (101, 99)), (2, (100, 105)), (2, (99, 117)), (2, (99, 97)), (2, (97, 108)), (2, (97, 100)), (2, (32, 113)), (2, (32, 112)), (2, (32, 111)), (1, (120, 101)), (1, (120, 99)), (1, (120, 32)), (1, (118, 111)), (1, (117, 115)), (1, (117, 103)), (1, (117, 100)), (1, (117, 32)), (1, (116, 114)), (1, (116, 105)), (1, (116, 46)), (1, (115, 115)), (1, (115, 109)), (1, (115, 99)), (1, (114, 111)), (1, (114, 99)), (1, (114, 46)), (1, (112, 115)), (1, (112, 111)), (1, (112, 32)), (1, (111, 115)), (1, (111, 109)), (1, (111, 105)), (1, (111, 102)), (1, (111, 99)), (1, (110, 117)), (1, (110, 103)), (1, (110, 100)), (1, (110, 99)), (1, (110, 97)), (1, (109, 112)), (1, (109, 109)), (1, (109, 105)), (1, (109, 101)), (1, (109, 99)), (1, (109, 97)), (1, (109, 46)), (1, (109, 44)), (1, (108, 112)), (1, (105, 117)), (1, (105, 114)), (1, (105, 111)), (1, (105, 108)), (1, (105, 99)), (1, (104, 101)), (1, (103, 110)), (1, (103, 105)), (1, (103, 32)), (1, (102, 117)), (1, (102, 105)), (1, (102, 102)), (1, (101, 113)), (1, (101, 105)), (1, (101, 104)), (1, (101, 100)), (1, (101, 97)), (1, (100, 117)), (1, (100, 97)), (1, (99, 116)), (1, (99, 101)), (1, (99, 99)), (1, (97, 117)), (1, (97, 114)), (1, (97, 110)), (1, (97, 103)), (1, (97, 101)), (1, (97, 46)), (1, (85, 116)), (1, (76, 111)), (1, (69, 120)), (1, (68, 117)), (1, (32, 116)), (1, (32, 114)), (1, (32, 102)), (1, (32, 85)), (1, (32, 69)), (1, (32, 68))]\n"
     ]
    }
   ],
   "source": [
    "stats = get_stats(tokens)\n",
    "print(stats)\n",
    "print(sorted(((v, k) for k, v in stats.items()), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_pair = max(stats, key=stats.get)\n",
    "top_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(ids, pair, idx):\n",
    "    # in the list of int(s) (ids), replace all consecutive occurences of pair with the new token idx\n",
    "    newIds = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(ids):\n",
    "        # if we are not at the very last position AND the pair matches, replace it\n",
    "        if i < len(ids)-1 and pair[0] == ids[i] and pair[1] == ids[i+1]:\n",
    "            newIds.append(idx)\n",
    "            i += 2\n",
    "        else:\n",
    "            newIds.append(ids[i])\n",
    "            i += 1\n",
    "            \n",
    "    return newIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76, 111, 114, 101, 109, 32, 105, 112, 115, 117, 109, 32, 100, 111, 108, 111, 114, 32, 115, 105, 256, 97, 109, 101, 116, 44, 32, 99, 111, 110, 115, 101, 99, 116, 101, 116, 117, 114, 32, 97, 100, 105, 112, 105, 115, 99, 105, 110, 103, 32, 101, 108, 105, 116, 44, 32, 115, 101, 100, 32, 100, 111, 32, 101, 105, 117, 115, 109, 111, 100, 32, 116, 101, 109, 112, 111, 114, 32, 105, 110, 99, 105, 100, 105, 100, 117, 110, 256, 117, 256, 108, 97, 98, 111, 114, 101, 32, 101, 256, 100, 111, 108, 111, 114, 101, 32, 109, 97, 103, 110, 97, 32, 97, 108, 105, 113, 117, 97, 46, 32, 85, 256, 101, 110, 105, 109, 32, 97, 100, 32, 109, 105, 110, 105, 109, 32, 118, 101, 110, 105, 97, 109, 44, 32, 113, 117, 105, 115, 32, 110, 111, 115, 116, 114, 117, 100, 32, 101, 120, 101, 114, 99, 105, 116, 97, 116, 105, 111, 110, 32, 117, 108, 108, 97, 109, 99, 111, 32, 108, 97, 98, 111, 114, 105, 115, 32, 110, 105, 115, 105, 32, 117, 256, 97, 108, 105, 113, 117, 105, 112, 32, 101, 120, 32, 101, 97, 32, 99, 111, 109, 109, 111, 100, 111, 32, 99, 111, 110, 115, 101, 113, 117, 97, 116, 46, 32, 68, 117, 105, 115, 32, 97, 117, 116, 101, 32, 105, 114, 117, 114, 101, 32, 100, 111, 108, 111, 114, 32, 105, 110, 32, 114, 101, 112, 114, 101, 104, 101, 110, 100, 101, 114, 105, 256, 105, 110, 32, 118, 111, 108, 117, 112, 116, 97, 116, 101, 32, 118, 101, 108, 105, 256, 101, 115, 115, 101, 32, 99, 105, 108, 108, 117, 109, 32, 100, 111, 108, 111, 114, 101, 32, 101, 117, 32, 102, 117, 103, 105, 97, 256, 110, 117, 108, 108, 97, 32, 112, 97, 114, 105, 97, 116, 117, 114, 46, 32, 69, 120, 99, 101, 112, 116, 101, 117, 114, 32, 115, 105, 110, 256, 111, 99, 99, 97, 101, 99, 97, 256, 99, 117, 112, 105, 100, 97, 116, 97, 256, 110, 111, 110, 32, 112, 114, 111, 105, 100, 101, 110, 116, 44, 32, 115, 117, 110, 256, 105, 110, 32, 99, 117, 108, 112, 97, 32, 113, 117, 105, 32, 111, 102, 102, 105, 99, 105, 97, 32, 100, 101, 115, 101, 114, 117, 110, 256, 109, 111, 108, 108, 105, 256, 97, 110, 105, 109, 32, 105, 100, 32, 101, 115, 256, 108, 97, 98, 111, 114, 117, 109, 46]\n",
      "length: 429\n"
     ]
    }
   ],
   "source": [
    "tokens = merge(tokens, top_pair, 256)\n",
    "print(tokens)\n",
    "print('length:', len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70, 105, 114, 115, 116, 32, 67, 105, 116, 105, 122, 101, 110, 58, 10, 66, 101, 102, 111, 114, 101, 32, 119, 101, 32, 112, 114, 111, 99, 101, 101, 100, 32, 97, 110, 121, 32, 102, 117, 114, 116, 104, 101, 114, 44, 32, 104, 101, 97, 114, 32, 109, 101, 32, 115, 112, 101, 97, 107, 46, 10, 10, 65, 108, 108, 58, 10, 83, 112, 101, 97, 107, 44, 32, 115, 112, 101, 97, 107, 46]\n",
      "1115394\n"
     ]
    }
   ],
   "source": [
    "text = open('tiny_shakespeare.txt', 'r', encoding='utf-8').read()\n",
    "tokens = list(text.encode('utf-8'))\n",
    "print(tokens[:80])\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging (101, 32) into a new token 256\n",
      "merging (116, 104) into a new token 257\n",
      "merging (116, 32) into a new token 258\n",
      "merging (115, 32) into a new token 259\n",
      "merging (100, 32) into a new token 260\n",
      "merging (44, 32) into a new token 261\n",
      "merging (111, 117) into a new token 262\n",
      "merging (101, 114) into a new token 263\n",
      "merging (105, 110) into a new token 264\n",
      "merging (121, 32) into a new token 265\n",
      "merging (97, 110) into a new token 266\n",
      "merging (58, 10) into a new token 267\n",
      "merging (111, 114) into a new token 268\n",
      "merging (111, 32) into a new token 269\n",
      "merging (101, 110) into a new token 270\n",
      "merging (10, 10) into a new token 271\n",
      "merging (97, 114) into a new token 272\n",
      "merging (32, 257) into a new token 273\n",
      "merging (111, 110) into a new token 274\n",
      "merging (108, 108) into a new token 275\n",
      "merging (104, 97) into a new token 276\n",
      "merging (44, 10) into a new token 277\n",
      "merging (46, 271) into a new token 278\n",
      "merging (105, 259) into a new token 279\n",
      "merging (101, 115) into a new token 280\n",
      "merging (121, 262) into a new token 281\n",
      "merging (32, 115) into a new token 282\n",
      "merging (116, 269) into a new token 283\n",
      "merging (266, 260) into a new token 284\n",
      "merging (111, 119) into a new token 285\n",
      "merging (101, 97) into a new token 286\n",
      "merging (32, 109) into a new token 287\n",
      "merging (32, 119) into a new token 288\n",
      "merging (111, 102) into a new token 289\n",
      "merging (32, 104) into a new token 290\n",
      "merging (264, 103) into a new token 291\n",
      "merging (111, 109) into a new token 292\n",
      "merging (32, 97) into a new token 293\n",
      "merging (99, 104) into a new token 294\n",
      "merging (257, 256) into a new token 295\n",
      "merging (115, 116) into a new token 296\n",
      "merging (32, 98) into a new token 297\n",
      "merging (110, 111) into a new token 298\n",
      "merging (105, 114) into a new token 299\n",
      "merging (102, 268) into a new token 300\n",
      "merging (118, 256) into a new token 301\n",
      "merging (101, 261) into a new token 302\n",
      "merging (105, 257) into a new token 303\n",
      "merging (273, 256) into a new token 304\n",
      "merging (115, 101) into a new token 305\n",
      "merging (108, 105) into a new token 306\n",
      "merging (84, 104) into a new token 307\n",
      "merging (275, 32) into a new token 308\n",
      "merging (114, 101) into a new token 309\n",
      "merging (115, 258) into a new token 310\n",
      "merging (97, 258) into a new token 311\n",
      "merging (65, 110) into a new token 312\n",
      "merging (73, 32) into a new token 313\n",
      "merging (101, 272) into a new token 314\n",
      "merging (105, 109) into a new token 315\n",
      "merging (105, 116) into a new token 316\n",
      "merging (111, 111) into a new token 317\n",
      "merging (103, 104) into a new token 318\n",
      "merging (97, 116) into a new token 319\n",
      "merging (105, 115) into a new token 320\n",
      "merging (108, 101) into a new token 321\n",
      "merging (263, 32) into a new token 322\n",
      "merging (262, 114) into a new token 323\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 324            # the desired final vocabulary size\n",
    "num_merges = vocab_size - 256\n",
    "ids = list(tokens)          # copy so we don't destroy the original list\n",
    "\n",
    "\n",
    "merges = {}                 # (int, int) -> (int)\n",
    "for i in range(num_merges):\n",
    "    stats = get_stats(ids)\n",
    "    pair = max(stats, key=stats.get)\n",
    "\n",
    "    idx = 256 + i\n",
    "    ids = merge(ids, pair, idx)\n",
    "\n",
    "    print(f'merging {pair} into a new token {idx}')\n",
    "    merges[pair] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {idx : bytes([idx]) for idx in range(256)}\n",
    "for (p0, p1), idx in merges.items():\n",
    "    vocab[idx] = vocab[p0] + vocab[p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token length: 1115394\n",
      "ids length: 736256\n",
      "compression ratio: 1.51x\n"
     ]
    }
   ],
   "source": [
    "print('token length:', len(tokens))\n",
    "print('ids length:', len(ids))\n",
    "print(f'compression ratio: {len(tokens)/len(ids):.2f}x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The tokenizer is a completely seperate, independent module from the LLM. It has its own training dataset of text (which could be different from that of the LLM), on which you train the vocabulary using the Byte Pair Encoding (BPE) algorithm. It then translates back and forth between raw text and sequences of tokens. The LLM later only ever sees the tokens and never directly deals with any text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/tokenizer_llm.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **decoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(ids):\n",
    "    # given ids (list of integers), return a Python string\n",
    "    tokens = b''.join(vocab[idx] for idx in ids)\n",
    "    text = tokens.decode('utf-8', errors='replace')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n"
     ]
    }
   ],
   "source": [
    "print(decode(ids)[:80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "    # given a string, return a list of integers (the tokens)\n",
    "    tokens = list(text.encode('utf-8'))\n",
    "\n",
    "    while len(tokens) > 1:\n",
    "        stats = get_stats(tokens)\n",
    "        pair = min(stats, key=lambda p: merges.get(p, float('inf')))\n",
    "        \n",
    "        # nothing else can be merged\n",
    "        if pair not in merges:\n",
    "            break   \n",
    "        idx = merges[pair]\n",
    "        tokens = merge(tokens, pair, idx)                \n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70, 299, 310, 67, 316, 105, 122, 270, 267, 66, 101, 300, 256, 119, 256, 112, 114, 111, 99, 101, 101, 260, 266, 265, 102, 117, 114, 257, 263, 261, 104, 314, 287, 256, 115, 112, 286, 107, 278, 65, 275, 267, 83, 112, 286, 107, 261, 115, 112, 286, 107, 278, 70, 299, 310, 67, 316, 105, 122, 270, 267, 89, 262, 32, 272, 256, 97, 308, 114, 280, 111, 108, 118, 101, 260, 114, 97, 257, 322, 283]\n"
     ]
    }
   ],
   "source": [
    "print(encode(text)[:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "val_text = 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.'\n",
    "print(val_text == decode(encode(val_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
